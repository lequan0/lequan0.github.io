---
title: "Lab 7.1 Non-linear regression"
author: "quan le"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Intro to Non-linear Regression

```{r}
# generates gaussian kernel from training data Z
# k(x,z) = exp(-(x-z)^2)
gaussk = function(X, Z, gamma=1) {
  return(exp(-gamma * (X%*%t(rep(1,length(Z))) - rep(1,length(X))%*%t(Z))^2))
}

# generates simple polynomial kernel from training data Z
polyk = function(X, Z, d, r=1, gamma=1) {
  return((r + gamma * (X%*%t(Z)))^d)
}

# kernel ridge regression function
kreg = function(K, y, lambdas) {
  alphas = matrix(NA, nrow = ncol(K), ncol = length(lambdas))
  fit = matrix(NA, nrow = length(y), ncol = length(lambdas))
  lambda.min = lambdas[1]
  min.err = Inf
  mse = rep(0, length(lambdas))
  
  for (i in 1:length(lambdas)) {
    alphas[,i] = solve(K + lambdas[i]*diag(nrow(K)), y)
    fit[,i] = K %*% alphas[,i]
    mse[i] = mean((y - fit[,i])^2)
    if (mse[i] < min.err) {
      min.err = mse[i]
      lambda.min = lambdas[i]
    }
  }
  return(list("fit"=fit, "alphas"=alphas, "mse"=mse, "lambda.min"=lambda.min))
}
```


```{r}
# generate stimulated data
n = 600
x = sort(runif(n, min = -1, max = 10))
# exponentially damped sine function + error
y = exp(-(x/5)^2)*cos(x) + rnorm(n, mean=0, sd=0.2) 

grid = exp(1)^seq(10,-1,length=10) # the sequence of lambda

test = sort(sample(1:length(x), length(x)/3))
train = (-test)

X = x[train]

polynames = c("quadratic", "cubic", "quartic", "sextic")
degrees = c(2,3,4,6)

train.mse = c()
test.mse = c()
for (i in 1:length(degrees)) {
  reg = kreg(polyk(X, X, degrees[i]), y[train], grid)
  plot(x[test], y[test], main=paste("test data", polynames[i], "regression"))
  lines(x[train], reg$fit[,match(reg$lambda.min, grid)], col="red")
  train.mse[i] = min(reg$mse)
  test.mse[i] = mean((y[test] - polyk(x[test], X, degrees[i]) %*% reg$alphas[,match(reg$lambda.min, grid)])^2)
}
poly.mse = data.frame(regression = polynames, 
                      train.mse = train.mse,
                      test.mse = test.mse)
print(poly.mse)
```


```{r}
gamma = 10^(-4:4)
train.mse = c()
test.mse = c()
for (i in 1:length(gamma)) {
  reg = kreg(gaussk(X, X, gamma[i]), y[train], grid)
  plot(x[test], y[test], main=paste("test data, regression with a gaussian rbf kernel, gamma =",gamma[i]))
  lines(x[train], reg$fit[,match(reg$lambda.min, grid)], col="blue")
  train.mse[i] = min(reg$mse)
  test.mse[i] = mean((y[test] - gaussk(x[test], X, gamma[i]) %*% reg$alphas[,match(reg$lambda.min, grid)])^2)
}
rbf.mse = data.frame(gamma = gamma,
                      train.mse = train.mse,
                      test.mse = test.mse)
print(rbf.mse) 
```

