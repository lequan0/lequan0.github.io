---
title: "Lab 19"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(titanic)
library(rpart)
library(ggplot2)
library(caret)
library(dplyr)
library(GGally)
library(rpart.plot)
# install.packages("remotes")
# remotes::install_github("grantmcdermott/parttree")
library(parttree)
# library(parsnip)
library(yardstick)
# library(randomForest)
```

# Trees


```{r}
# Classification and Regression Trees (CART)

# Look at data!
head(titanic_train)
?titanic_train

titanic_train$Survived = as.factor(titanic_train$Survived)

titanic_train %>% 
  ggpairs(columns = c("Pclass",
                      "Sex",
                      "Age",
                      "Fare"),
          mapping = aes(color = Survived))
```


```{r}
# Decision tree model
treeModel = rpart(Survived ~ Pclass + Age + Fare + Sex, data=titanic_train, method="class", xval=5, cp=.005)
par(cex = 0.6)
plot(treeModel,margin=.05)
text(treeModel,use.n=TRUE)

summary(treeModel)
par(cex = 1)
plotcp(treeModel)
```


```{r}
# Some nicer plots
prp(treeModel)

rpart.plot(treeModel, box.palette="RdBu", shadow.col="gray", nn=TRUE)
```


## Plotting decision boundaries
```{r}
# Plotting decision boundaries

# Create a model with 2 predictors
treeModel = rpart(Survived ~ Pclass + Age, data=titanic_train, method="class", xval=5, cp=.00005)


# Plot decision boundaries
titanic_train %>%
  ggplot(aes(x=Pclass, y=Age)) +
  geom_jitter(aes(col=Survived), alpha=0.7) +
  geom_parttree(data = treeModel, aes(fill=Survived), alpha = 0.1) +
  theme_minimal()
```


```{r}
# What happens if we tweak the complexity parameter a.k.a. cp
# cp = 0.01
treeModel = rpart(Survived ~ Pclass + Age, data=titanic_train, method="class", xval=5, cp=.01)

# Plot decision boundaries
titanic_train %>%
  ggplot(aes(x=Pclass, y=Age)) +
  geom_jitter(aes(col=Survived), alpha=0.7) +
  geom_parttree(data = treeModel, aes(fill=Survived), alpha = 0.1) +
  theme_minimal()
```


```{r}
# cp = 0.1
treeModel = rpart(Survived ~ Pclass + Age, data=titanic_train, method="class", xval=5, cp=.1)


# Plot decision boundaries
titanic_train %>%
  ggplot(aes(x=Pclass, y=Age)) +
  geom_jitter(aes(col=Survived), alpha=0.7) +
  geom_parttree(data = treeModel, aes(fill=Survived), alpha = 0.1) +
  theme_minimal()
```


```{r}
# Let us split into training and test sets
## 75% of the sample size
train.index <- createDataPartition(titanic_train$Survived, p = .75, list = FALSE)
train <- titanic_train[ train.index,]
test  <- titanic_train[-train.index,]

# Train a model and check performance on the test set
treeModel = rpart(Survived ~ Pclass + Age, data=train, method="class", xval=5, cp=.01)

# Plot decision boundaries
train %>%
  ggplot(aes(x=Pclass, y=Age)) +
  geom_jitter(aes(col=Survived), alpha=0.7) +
  geom_parttree(data = treeModel, aes(fill=Survived), alpha = 0.1) +
  theme_minimal()

surv_pred <- predict(treeModel, newdata=test, type='class')
surv_pred
confusionMatrix(surv_pred, test$Survived)
```


```{r}
# plotting the confusion matrix
trueAndPredFr <- data.frame(surv_pred, test$Survived)
confMat <- conf_mat(trueAndPredFr, truth=test.Survived, estimate=surv_pred)

autoplot(confMat, type = "heatmap") +
  scale_fill_gradient(low="#D6EAF8",high = "#2E86C1") +
  theme(legend.position = "right")

# Take home exercise: Can you tune cp using a train and validation set, and then
# test the performance on a test set?
```
